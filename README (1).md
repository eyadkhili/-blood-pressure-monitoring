# ðŸ©º SystÃ¨me de Surveillance de Pression ArtÃ©rielle avec Kafka

## ðŸ“‹ Description du Projet

Ce projet implÃ©mente un systÃ¨me complet de surveillance des donnÃ©es de pression artÃ©rielle des patients en temps rÃ©el. Il utilise le standard **FHIR** (Fast Healthcare Interoperability Resources) pour gÃ©nÃ©rer des observations mÃ©dicales, **Apache Kafka** pour le streaming de donnÃ©es, **Elasticsearch** pour l'indexation des anomalies, et **Kibana** pour la visualisation.

### Architecture du SystÃ¨me

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FHIR Generator  â”‚â”€â”€â”€â”€â–¶â”‚  Kafka  â”‚â”€â”€â”€â”€â–¶â”‚   Consumer   â”‚â”€â”€â”€â”€â–¶â”‚ Elasticsearch â”‚
â”‚   (producer.py) â”‚     â”‚  Topic  â”‚     â”‚ (consumer.py)â”‚     â”‚    + Kibana   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                               â”‚
                                               â–¼
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚ Consumer ML (IA)     â”‚
                                    â”‚ (consumer_ml.py)     â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ› ï¸ PrÃ©requis

Avant de commencer, assurez-vous d'avoir installÃ© :

- **Docker** et **Docker Compose** (version 3.8+)
- **Python 3.10+**
- **pip** (gestionnaire de paquets Python)

---

## ðŸš€ Guide de Lancement - Ã‰tape par Ã‰tape

### Ã‰tape 1 : Cloner ou PrÃ©parer le Projet

CrÃ©ez un dossier pour votre projet et placez-y tous les fichiers :

```bash
mkdir blood-pressure-monitoring
cd blood-pressure-monitoring
```

Fichiers requis dans le dossier :
- `docker-compose.yml`
- `producer.py`
- `consumer.py`
- `consumer_ml.py`
- `fhir_generator.py`
- `train_ml.py`
- `requirements.txt`

---

### Ã‰tape 2 : Installation des DÃ©pendances Python

```bash
# CrÃ©er un environnement virtuel (recommandÃ©)
python -m venv venv

# Activer l'environnement virtuel
# Sur Windows :
venv\Scripts\activate
# Sur Linux/Mac :
source venv/bin/activate

# Installer toutes les dÃ©pendances
pip install -r requirements.txt
```

---

### Ã‰tape 3 : DÃ©marrer l'Infrastructure Docker

Lancez tous les services (Zookeeper, Kafka, Elasticsearch, Kibana) :

```bash
docker-compose up -d
```

**VÃ©rification du statut des conteneurs :**

```bash
docker-compose ps
```

Vous devriez voir 4 conteneurs en Ã©tat "Up" :
- `zookeeper`
- `kafka`
- `elasticsearch`
- `kibana`

**Attendre que tous les services soient prÃªts (~30-60 secondes) :**

```bash
# VÃ©rifier que Elasticsearch rÃ©pond
curl http://localhost:9200

# VÃ©rifier que Kafka est prÃªt
docker logs kafka 2>&1 | grep "started"
```

---

### Ã‰tape 4 : Lancer le Consumer (Terminal 1)

Ouvrez un **premier terminal** et lancez le consumer qui Ã©coute les messages Kafka :

```bash
# Activer l'environnement virtuel si nÃ©cessaire
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

# Lancer le consumer
python consumer.py
```

Vous verrez :
```
ðŸ“¡ Consumer prÃªt. Affichage dÃ©taillÃ© activÃ©...
```

Le consumer va :
- Ã‰couter le topic Kafka `blood_pressure_topic`
- Indexer les anomalies (hypertension, hypotension, crise) dans Elasticsearch
- Sauvegarder les donnÃ©es normales dans `normal_data/patients_sains.json`

---

### Ã‰tape 5 : Lancer le Producer (Terminal 2)

Ouvrez un **deuxiÃ¨me terminal** et lancez le producer :

```bash
# Activer l'environnement virtuel
source venv/bin/activate  # Linux/Mac

# Lancer le producer (mode continu)
python producer.py

# Ou avec des options personnalisÃ©es :
python producer.py -i 10 -p 5      # 5 patients toutes les 10 secondes
python producer.py -n 3            # Seulement 3 batches puis arrÃªt
```

**Options disponibles :**
| Option | Description | DÃ©faut |
|--------|-------------|--------|
| `-i`, `--interval` | Intervalle entre les batches (secondes) | 30 |
| `-p`, `--patients` | Nombre de patients par batch | 10 |
| `-n`, `--num-batches` | Nombre total de batches (null = infini) | None |

Vous verrez des messages comme :
```
âœ… [14:32:15] Jean Dupont               | BP: 115/75 | normal               | Paris
ðŸŸ  [14:32:15] Marie Martin              | BP: 135/85 | hypertension_stage_1 | Lyon
ðŸš¨ [14:32:15] Pierre Durand             | BP: 185/125| hypertensive_crisis  | Marseille
```

---

### Ã‰tape 6 : AccÃ©der Ã  Kibana pour la Visualisation

1. Ouvrez votre navigateur et allez sur : **http://localhost:5601**

2. **CrÃ©er un Data View (Index Pattern) :**
   - Menu â†’ Stack Management â†’ Data Views
   - Cliquer sur "Create data view"
   - Name : `blood_pressure_anomalies`
   - Index pattern : `blood_pressure_anomalies`
   - Timestamp field : `timestamp`
   - Cliquer sur "Save data view to Kibana"

3. **Explorer les donnÃ©es :**
   - Menu â†’ Discover
   - SÃ©lectionner le data view `blood_pressure_anomalies`
   - Vous verrez toutes les anomalies indexÃ©es

4. **CrÃ©er un Dashboard :**
   - Menu â†’ Dashboard â†’ Create dashboard
   - Ajouter des visualisations :
     - **Pie chart** : Distribution par `risk_level`
     - **Bar chart** : Anomalies par `city`
     - **Line chart** : Ã‰volution temporelle
     - **Map** : RÃ©partition gÃ©ographique (champ `location`)
     - **Data table** : Liste des patients critiques

---

### Ã‰tape 7 (Optionnel) : Activer le Module Machine Learning

#### 7.1 EntraÃ®ner le modÃ¨le

Attendez d'avoir accumulÃ© des donnÃ©es normales, puis :

```bash
python train_ml.py
```

Cela crÃ©e le fichier `blood_pressure_model.pkl`.

#### 7.2 Lancer le Consumer ML (Terminal 3)

```bash
python consumer_ml.py
```

Le consumer ML prÃ©dit le niveau de risque en temps rÃ©el :
```
ðŸ”® IA -> BP: 145/92 | RISQUE PRÃ‰DIT: High
ðŸ”® IA -> BP: 118/78 | RISQUE PRÃ‰DIT: Low
```

Les prÃ©dictions sont indexÃ©es dans : `blood_pressure_ml_predictions`

---

## ðŸ“Š Niveaux de Risque et CatÃ©gories

| CatÃ©gorie | Systolique (mmHg) | Diastolique (mmHg) | Niveau de Risque |
|-----------|-------------------|--------------------| -----------------|
| Normal | < 120 | ET < 80 | - (archivÃ© localement) |
| Elevated | 120-129 | ET < 80 | Moderate |
| Hypertension Stage 1 | 130-139 | OU 80-89 | Moderate |
| Hypertension Stage 2 | â‰¥ 140 | OU â‰¥ 90 | High |
| Hypertensive Crisis | > 180 | ET/OU > 120 | Critical |
| Hypotension | < 90 | OU < 60 | Low |

---

## ðŸ“ Structure des Fichiers

```
blood-pressure-monitoring/
â”‚
â”œâ”€â”€ docker-compose.yml      # Configuration Docker (Kafka, ES, Kibana)
â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â”‚
â”œâ”€â”€ fhir_generator.py       # GÃ©nÃ©ration des messages FHIR
â”œâ”€â”€ producer.py             # Producteur Kafka
â”œâ”€â”€ consumer.py             # Consommateur + indexation ES
â”‚
â”œâ”€â”€ train_ml.py             # EntraÃ®nement du modÃ¨le ML
â”œâ”€â”€ consumer_ml.py          # PrÃ©dictions en temps rÃ©el
â”œâ”€â”€ blood_pressure_model.pkl # ModÃ¨le ML sauvegardÃ©
â”‚
â””â”€â”€ normal_data/            # Dossier des donnÃ©es normales
    â””â”€â”€ patients_sains.json
```

---

## ðŸ”§ Commandes Utiles

### Gestion Docker

```bash
# DÃ©marrer tous les services
docker-compose up -d

# ArrÃªter tous les services
docker-compose down

# Voir les logs d'un service
docker logs kafka -f
docker logs elasticsearch -f

# RedÃ©marrer un service
docker-compose restart kafka

# Supprimer les volumes (reset complet)
docker-compose down -v
```

### VÃ©rification des Services

```bash
# Tester Elasticsearch
curl http://localhost:9200/_cluster/health?pretty

# Lister les index Elasticsearch
curl http://localhost:9200/_cat/indices?v

# Compter les documents dans l'index
curl http://localhost:9200/blood_pressure_anomalies/_count

# Voir les topics Kafka
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092
```

### RÃ©initialisation

```bash
# Supprimer l'index Elasticsearch
curl -X DELETE http://localhost:9200/blood_pressure_anomalies

# Supprimer les donnÃ©es locales
rm -rf normal_data/

# Supprimer le modÃ¨le ML
rm blood_pressure_model.pkl
```

---

## â“ DÃ©pannage

### Le Consumer ne reÃ§oit pas de messages

1. VÃ©rifiez que Kafka est bien dÃ©marrÃ© : `docker logs kafka`
2. VÃ©rifiez que le Producer envoie bien : regardez les logs du Producer
3. Changez le `group.id` dans `consumer.py` (incrÃ©mentez la version)

### Elasticsearch ne dÃ©marre pas

1. VÃ©rifiez la mÃ©moire disponible (ES nÃ©cessite ~512MB)
2. Consultez les logs : `docker logs elasticsearch`
3. Augmentez la mÃ©moire Docker si nÃ©cessaire

### Kibana affiche "No results found"

1. VÃ©rifiez que des anomalies ont Ã©tÃ© indexÃ©es :
   ```bash
   curl http://localhost:9200/blood_pressure_anomalies/_count
   ```
2. VÃ©rifiez le time range dans Kibana (Ã©tendez-le si nÃ©cessaire)
3. RecrÃ©ez le Data View si le mapping a changÃ©

### Erreur "confluent-kafka not installed"

```bash
pip install confluent-kafka --break-system-packages
# ou dans un venv :
pip install confluent-kafka
```

---

## ðŸ“ Auteurs

Projet rÃ©alisÃ© dans le cadre du cours de Big Data / SystÃ¨mes DistribuÃ©s.

---

## ðŸ“š Ressources

- [Standard FHIR](https://www.hl7.org/fhir/overview.html)
- [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
- [Elasticsearch Guide](https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html)
- [Kibana Guide](https://www.elastic.co/guide/en/kibana/current/index.html)
